{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Integrated Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running `transformer.ipynb`, you should have a model saved at the checkpoint path below. The first part of this notebook just reads in the data into a data loader, teh second part runs `IntegratedGradients` from the captum package and then saves the output into a csv for visualization within R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../data/blooms.csv\"\n",
    "checkpoint = \"lightning_logs/version_0/checkpoints/epoch=69-step=1680.ckpt\"\n",
    "output_path = \"../data/attributions.csv\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads in the data. We've increased the dataloader size because we aren't training, so don't need to be so stingy with GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer import LinearData, Transformer, LitTransformer\n",
    "\n",
    "samples_df = pd.read_csv(input_path)\n",
    "dataset = LinearData(samples_df)\n",
    "loader = DataLoader(dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs the attribution and saves it to the `output_path` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "lit_model = LitTransformer.load_from_checkpoint(checkpoint, model = Transformer()).to(device)\n",
    "\n",
    "def forward(model):\n",
    "  return lambda x: model(x)[1]\n",
    "\n",
    "ig = IntegratedGradients(forward(lit_model.model))\n",
    "x, y = next(iter(loader))\n",
    "i_hat = ig.attribute(x.to(device))\n",
    "np.savetxt(output_path, np.reshape(i_hat, (64, -1)).cpu(), delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
