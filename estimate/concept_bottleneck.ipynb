{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Bottleneck on Microbiome Trajectories\n",
    "\n",
    "This code is almost the same as for the plain transformer. The only difference in our loader is that we also need to keep track of the dense concept annotations, which are saved in to the `concepts` DataFrame. As before, you can download the data from [this link](https://github.com/krisrs1128/interpretability_review/tree/main/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from concept import ConceptData\n",
    "\n",
    "# use the data from ../generate\n",
    "torch.manual_seed(20240210)\n",
    "subsample_size = 500\n",
    "samples_df = pd.read_csv(\"../data/blooms.csv\", nrows=subsample_size)\n",
    "concepts = pd.read_csv(\"../data/concepts.csv\", nrows=subsample_size)\n",
    "\n",
    "dataset = ConceptData(samples_df, concepts)\n",
    "train = Subset(dataset, torch.arange(int(0.75 * subsample_size)))\n",
    "validation = Subset(dataset, torch.arange(int(0.75 * subsample_size), subsample_size))\n",
    "loaders = {\n",
    "  \"train\": DataLoader(train, batch_size=16),\n",
    "  \"validate\": DataLoader(validation, batch_size=16)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are training the model for longer, because the concept model takes longer to converge. You can view all the evaluation metrics by starting a tensorboard viewer in the `concept_logs` directory created by the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from concept import ConceptBottleneck, LitConcept\n",
    "\n",
    "concepts\n",
    "model = ConceptBottleneck()\n",
    "lit_model = LitConcept(model)\n",
    "trainer = L.Trainer(max_epochs=70, default_root_dir=\"concept_logs\")\n",
    "trainer.fit(lit_model, loaders[\"train\"], loaders[\"validate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lit_model.model.eval()\n",
    "p_hat = []\n",
    "with torch.no_grad():\n",
    "  for x, c, _ in loaders[\"train\"]:\n",
    "    p_hat.append(lit_model.model(x)[1])\n",
    "  for x, c, _ in loaders[\"validate\"]:\n",
    "    p_hat.append(lit_model.model(x)[1])\n",
    "\n",
    "pd.DataFrame(torch.concatenate(p_hat)).to_csv(\"../data/p_hat_concept.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
